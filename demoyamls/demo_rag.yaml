input:
    question: ""
    mode: "cli"
vectorstore_retriever:
    kind: weaviate
    vectorstore_provider: dkubex
    embedding_class: HuggingFaceEmbedding                       # Use 'HuggingFaceEmbedding' for embedding models from HuggingFace, or 'OpenAIEmbedding' for OpenAI embeddings
    embedding_model: 'BAAI/bge-large-en-v1.5'                   # Embedding model name
    llmkey: ""                                                  # API key for the embedding model (if required)
    textkey: 'paperchunks'
    top_k: 3
prompt_builder:
    prompt_str: ""
    prompt_file: ""
nodes_sorter:
    max_sources: 3
contexts_joiner:
    separator: "\n\n"
chat_engine:
    llm: dkubex                                                 # Use 'dkubex' for DKubeX deployments and 'openai' to use OpenAI API
    url: "http://44.192.125.133:30002/v1/"
    llmkey: "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyIjoib2NkbGdpdCIsInR5cGUiOiJhcGkiLCJpZCI6Ii9kZXBsb3ltZW50L2xsYW1hM2Nsb3VkLyJ9.ZSnl6lXcxjLGYxEGfTsea35nV7ly7F938Vd8NwvTHuc"
    #url: "https://a39d44034b53541deb754ffe25ee0d01-6a9d515a94d26bb2.elb.us-east-1.amazonaws.com/deployment/8/llama3/"
    #llmkey: "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyIjoib2NkbGdpdCIsInR5cGUiOiJhcGkiLCJpZCI6Ii9kZXBsb3ltZW50L2xsYW1hMy8ifQ.yAXx7495nT2Gb_UPR70YWQBZ2znEF1d1JSRQDDuJmA8"
    window_size: 2
    max_tokens: 2048                                            # Maximum number of tokens to be used for generating responses
securellm:                                                      # SecureLLM configuration. Comment out this section if not using SecureLLM
    appkey: "sk-f7v7coy-zv2u7na-t2ykj2q-vni2yuy"
    #appkey: "sk-rnmfwdi-fv6uqny-tq3lloq-4hhwm2a"                # Provide SecureLLM Application Key to be used
    dkubex_url: "https://a39d44034b53541deb754ffe25ee0d01-6a9d515a94d26bb2.elb.us-east-1.amazonaws.com"                   # Provide the URL of the DKubeX deployment
tracking:
  experiment: "climate_chat"
