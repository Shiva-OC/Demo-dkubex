vectorstore_reader:
    kind: weaviate
    provider: dkubex
    properties:
    - paperchunks
    - dkubexfm
questions_generator:                                        # Generates the questions to be used for the dataset evaluation
    prompt_str: "default"
    prompt_file: ""
    num_questions_per_chunk: 1                              # Number of questions to be generated per chunk
    max_chunks: 5                                         # Maximum number of chunks to be used for question generation
    llm: openai                                             # Language model to be used for question generation. To use OpenAI to generate questions, use 'openai'. To use DKubeX LLM deployment, use 'dkubex'
    llmkey: "s**************************e" # If using DKubeX deployment, provide the serving_token for the deployment. If using OpenAI, provide the OpenAI API key
    llmurl: ""                                              # Endpoint URL for the DKubeX LLM deployment which will be used for generating responses. If using OpenAI, keep blank.
    max_tokens: 2048                                        # Maximum number of tokens to be used for generating questions
retrieval_evaluator:
    vector_retriever:
        kind: weaviate
        vectorstore_provider: dkubex
        textkey: paperchunks
        embedding_class: HuggingFaceEmbedding               # Use 'HuggingFaceEmbedding' for embedding models from HuggingFace, or 'OpenAIEmbedding' for OpenAI embeddings
        embedding_model: "BAAI/bge-large-en-v1.5"           # Embedding model name
        llmkey: ""                                          # API key for the embedding model (if required)
        similarity_top_k: 3
    metrics:
    - mrr
    - hit_rate
semantic_similarity_evaluator:
    prompt_str: "default"
    prompt_file: ""
    llm: dkubex
    url: "http://44.192.125.133:30002/v1/"
    llmkey: "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyIjoib2NkbGdpdCIsInR5cGUiOiJhcGkiLCJpZCI6Ii9kZXBsb3ltZW50L2xsYW1hM2Nsb3VkLyJ9.ZSnl6lXcxjLGYxEGfTsea35nV7ly7F938Vd8NwvTHuc"
    max_tokens: 2048                                        # Maximum number of tokens to be used for generating groundtruth responses
    rag_configuration: "/home/ocdlgit/demoyamls/demo_rag.yaml"       # Absolute path to the RAG config (query.yaml) file. This file contains the details of the LLM which is to be evaluated against the groundtruth responses.
    metrics:
    - similarity_score
tracking:
    experiment: "climate_eval"
