Deploying Embedding model in DKubex
--------------------------------------

Command to deploy embedding model from catalog
----------------------------------------------
d3x emb deploy --n {name of the model} --model {name of the model from catalog} --token ${HF_TOKEN} --publish(if you want it to be published)

Command to deploy embedding model from HF model registry
--------------------------------------------------------
d3x emb deploy --n {name of the model} --config {path to config.yaml} --type=acclerator_type --token ${HF_TOKEN} --publish(if you want it to be published)

Add `--sky` option to above command for deploying model on cloud.


OPTIONS:
  -n, --name TEXT           name of the deployment  [required]
  -m, --model TEXT          name or path of the model to deploy for embeddings
  --base_model TEXT         base model name
  --token TEXT              hugging face token
  --config TEXT             github raw content url or local config path
  --mlflow TEXT             name of the mlflow registered model along with
                            version (example: diffusion:1)
  --image TEXT              customized docker image for deployment
  --type TEXT               instance type
  --min_replicas TEXT       minimum replicas
  --max_replicas TEXT       maximum replicas
  --publish                 publish the deployment
  -o, --output [yaml|json]  supported only json,yaml
  -sky, --remote-sky        If the model should be deployed on remote sky
                            cluster.
  --sky-accelerator TEXT    accelerator for remote sky cluster
  --sky-yaml TEXT           Path to custom yaml file for sky serve.


---------------------------------------------------------------------------------------------------------------------------
Example config
---------------------------------------------------------------------------------------------------------------------------
BAAI--bge-large-en-v1-5

deployment_config:
  autoscaling_config:
    min_replicas: 1
    initial_replicas: 1
    max_replicas: 2
    target_num_ongoing_requests_per_replica: 10
    metrics_interval_s: 10.0
    look_back_period_s: 30.0
    smoothing_factor: 0.5
    downscale_delay_s: 300.0
    upscale_delay_s: 5.0
  # max_concurrent_queries: 1
  ray_actor_options:
    resources:
      accelerator_type_a10: 0
engine_config:
  model_id: BAAI/bge-large-en-v1.5
  hf_model_id: BAAI/bge-large-en-v1.5
  type: EmbeddingEngine
  engine_kwargs:
    trust_remote_code: true
    #max_num_batched_tokens: 4096
    #max_num_seqs: 64
    #gpu_memory_utilization: 0.85
  # max_total_tokens: 4096
  max_total_tokens: 512
  # max_batch_size: 10
scaling_config:
  num_workers: 1
  num_gpus_per_worker: 0
  num_cpus_per_worker: 1
  placement_strategy: "STRICT_PACK"
  resources_per_worker:
    accelerator_type_a10: 0
